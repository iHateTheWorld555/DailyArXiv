---
title: Latest 6 Papers - January 13, 2026
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## Efficient Diffusion Models
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[When quantum resources backfire: Non-gaussianity and symplectic coherence in noisy bosonic circuits](https://arxiv.org/abs/2510.07264v2)** | 2026-01-09 | 64 pages, 6 figures |
| **[Mobility Trajectories from Network-Driven Markov Dynamics](https://arxiv.org/abs/2601.06020v1)** | 2026-01-09 | 22 pages, 6 figures |
| **[From Fact to Judgment: Investigating the Impact of Task Framing on LLM Conviction in Dialogue Systems](https://arxiv.org/abs/2511.10871v2)** | 2026-01-09 | 11 pages, 3 figures |
| **[Co-Training Vision Language Models for Remote Sensing Multi-task Learning](https://arxiv.org/abs/2511.21272v2)** | 2026-01-09 | 14 pages, 6 figures |
| **[Don't Break the Cache: An Evaluation of Prompt Caching for Long-Horizon Agentic Tasks](https://arxiv.org/abs/2601.06007v1)** | 2026-01-09 | 15 pages, 8 figures |
| **[Discriminative-Generative Target Speaker Extraction with Decoder-Only Language Models](https://arxiv.org/abs/2601.06006v1)** | 2026-01-09 | 16 pages,6 figures |

## Transformer Compression
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Co-Training Vision Language Models for Remote Sensing Multi-task Learning](https://arxiv.org/abs/2511.21272v2)** | 2026-01-09 | 14 pages, 6 figures |
| **[CyberGFM: Graph Foundation Models for Lateral Movement Detection in Enterprise Networks](https://arxiv.org/abs/2601.05988v1)** | 2026-01-09 | <details><summary>17 pa...</summary><p>17 pages; 11 figures; 8 tables</p></details> |
| **[Monadic Context Engineering](https://arxiv.org/abs/2512.22431v3)** | 2026-01-09 | <details><summary>The a...</summary><p>The authors have decided to withdraw this manuscript, as the ideas presented in the paper are not yet sufficiently mature and require further development and refinement</p></details> |
| **[Reflect3r: Single-View 3D Stereo Reconstruction Aided by Mirror Reflections](https://arxiv.org/abs/2509.20607v2)** | 2026-01-09 | <details><summary>3DV 2...</summary><p>3DV 2026. Code and Data Available at https://jingwu2121.github.io/reflect3r/</p></details> |
| **[Adapting Vision Transformers to Ultra-High Resolution Semantic Segmentation with Relay Tokens](https://arxiv.org/abs/2601.05927v1)** | 2026-01-09 | <details><summary>13 pa...</summary><p>13 pages +3 pages of suppmat</p></details> |
| **[Distilling Lightweight Domain Experts from Large ML Models by Identifying Relevant Subspaces](https://arxiv.org/abs/2601.05913v1)** | 2026-01-09 | <details><summary>20 pa...</summary><p>20 pages + supplement</p></details> |

## Fast Inference
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Discriminative-Generative Target Speaker Extraction with Decoder-Only Language Models](https://arxiv.org/abs/2601.06006v1)** | 2026-01-09 | 16 pages,6 figures |
| **[The Molecular Structure of Thought: Mapping the Topology of Long Chain-of-Thought Reasoning](https://arxiv.org/abs/2601.06002v1)** | 2026-01-09 | Preprint |
| **[Adaptive Conditional Contrast-Agnostic Deformable Image Registration with Uncertainty Estimation](https://arxiv.org/abs/2601.05981v1)** | 2026-01-09 | <details><summary>Accep...</summary><p>Accepted by ieee transactions on Medical Imaging</p></details> |
| **[Efficient Bayesian Computation Using Plug-and-Play Priors for Poisson Inverse Problems](https://arxiv.org/abs/2503.16222v2)** | 2026-01-09 | 35 pages, 19 figures |
| **[Distilling Feedback into Memory-as-a-Tool](https://arxiv.org/abs/2601.05960v1)** | 2026-01-09 | <details><summary>Code:...</summary><p>Code: https://github.com/vicgalle/feedback-memory-as-a-tool Data: https://huggingface.co/datasets/vicgalle/rubric-feedback-bench</p></details> |
| **[Let Me Think! A Long Chain-of-Thought Can Be Worth Exponentially Many Short Ones](https://arxiv.org/abs/2505.21825v2)** | 2026-01-09 | <details><summary>Publi...</summary><p>Published at NeurIPS 2025</p></details> |

