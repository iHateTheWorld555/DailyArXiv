---
title: Latest 6 Papers - February 04, 2026
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## Efficient Diffusion Models
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Reward-free Alignment for Conflicting Objectives](https://arxiv.org/abs/2602.02495v1)** | 2026-02-02 | 27 pages |
| **[MEG-XL: Data-Efficient Brain-to-Text via Long-Context Pre-Training](https://arxiv.org/abs/2602.02494v1)** | 2026-02-02 | <details><summary>19 pa...</summary><p>19 pages, 8 figures, 5 tables</p></details> |
| **[PixelGen: Pixel Diffusion Beats Latent Diffusion with Perceptual Loss](https://arxiv.org/abs/2602.02493v1)** | 2026-02-02 | <details><summary>Proje...</summary><p>Project Pages: https://zehong-ma.github.io/PixelGen/</p></details> |
| **[DESIGNER: Design-Logic-Guided Multidisciplinary Data Synthesis for LLM Reasoning](https://arxiv.org/abs/2508.12726v6)** | 2026-02-02 | <details><summary>Accep...</summary><p>Accepted to ICLR 2026. Project page: https://attention-is-all-i-need.github.io/Design-Logic-Reasoning</p></details> |
| **[RLAnything: Forge Environment, Policy, and Reward Model in Completely Dynamic RL System](https://arxiv.org/abs/2602.02488v1)** | 2026-02-02 | <details><summary>Code:...</summary><p>Code: https://github.com/Gen-Verse/Open-AgentRL</p></details> |
| **[Expanding the Capabilities of Reinforcement Learning via Text Feedback](https://arxiv.org/abs/2602.02482v1)** | 2026-02-02 | 43 pages, 6 figures |

## Transformer Compression
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[DESIGNER: Design-Logic-Guided Multidisciplinary Data Synthesis for LLM Reasoning](https://arxiv.org/abs/2508.12726v6)** | 2026-02-02 | <details><summary>Accep...</summary><p>Accepted to ICLR 2026. Project page: https://attention-is-all-i-need.github.io/Design-Logic-Reasoning</p></details> |
| **[Multi-head automated segmentation by incorporating detection head into the contextual layer neural network](https://arxiv.org/abs/2602.02471v1)** | 2026-02-02 | <details><summary>8 pag...</summary><p>8 pages, 3 figures, 1 table</p></details> |
| **[Age-Aware Edge-Blind Federated Learning via Over-the-Air Aggregation](https://arxiv.org/abs/2602.02469v1)** | 2026-02-02 | <details><summary>To ap...</summary><p>To appear in IEEE ICC 2026</p></details> |
| **[SelvaMask: Segmenting Trees in Tropical Forests and Beyond](https://arxiv.org/abs/2602.02426v1)** | 2026-02-02 | 22 pages, 8 figures |
| **[David vs. Goliath: Verifiable Agent-to-Agent Jailbreaking via Reinforcement Learning](https://arxiv.org/abs/2602.02395v1)** | 2026-02-02 | <details><summary>Under...</summary><p>Under review. 8 main pages, 2 figures, 2 tables. Appendix included</p></details> |
| **[Generalization or Hallucination? Understanding Out-of-Context Reasoning in Transformers](https://arxiv.org/abs/2506.10887v4)** | 2026-02-02 | <details><summary>NeurI...</summary><p>NeurIPS 2025, first three authors contributed equally</p></details> |

## Fast Inference
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[New explanations and inference for least angle regression](https://arxiv.org/abs/2602.02491v1)** | 2026-02-02 | 50 pages, 9 figures |
| **[Expanding the Capabilities of Reinforcement Learning via Text Feedback](https://arxiv.org/abs/2602.02482v1)** | 2026-02-02 | 43 pages, 6 figures |
| **[Relationship-Aware Hierarchical 3D Scene Graph for Task Reasoning](https://arxiv.org/abs/2602.02456v1)** | 2026-02-02 | ICRA 2026, 8 pages |
| **[Energy-Efficient Neuromorphic Computing for Edge AI: A Framework with Adaptive Spiking Neural Networks and Hardware-Aware Optimization](https://arxiv.org/abs/2602.02439v1)** | 2026-02-02 | <details><summary>8 pag...</summary><p>8 pages, 4 figures, 4 tables. Submitted to IEEE Transactions on Neural Networks and Learning Systems (TNNLS)</p></details> |
| **[FS-DFM: Fast and Accurate Long Text Generation with Few-Step Diffusion Language Models](https://arxiv.org/abs/2509.20624v3)** | 2026-02-02 | <details><summary>Accep...</summary><p>Accepted to ICLR 2026</p></details> |
| **[PRISM: Performer RS-IMLE for Single-pass Multisensory Imitation Learning](https://arxiv.org/abs/2602.02396v1)** | 2026-02-02 | <details><summary>10 pa...</summary><p>10 pages main text and 4 figures, and 11 pages appendix and 10 figures, total 21 pages and 14 figures</p></details> |

